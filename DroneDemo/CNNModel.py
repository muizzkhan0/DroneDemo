<<<<<<< HEAD
<<<<<<< HEAD
# -*- coding: utf-8 -*-
"""COE70B Data Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12W1-3t_YDnDUGKUz5l8tGftkE9gaOtLX
"""

import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt

# This line loads the data in batches of 32 and also does a variety of other useful functions on the data
data = tf.keras.utils.image_dataset_from_directory('Sorted_Images');

data_iterator = data.as_numpy_iterator()

class_labels = ["No line","Sharp Left","Sharp Right","Slight Left","Slight Right","Straight"]

data = data.map(lambda x,y: (x/255, y))
scaled_iterator = data.as_numpy_iterator();

train_size = 12
val_size = 3
test_size = 3

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense
from tensorflow.keras.optimizers import Adam

# initialize the number of epochs to train for, initial learning rate,and batch size
EPOCHS = 5
INIT_LR = 1e-3
BS = 17

# initialize the model
print("[INFO] compiling model...")
model = Sequential()

#first set of CONV=> RELU => POOL layers
model.add(Conv2D(20, (5, 5), padding="same", input_shape=(256,256,3))) #256x256 image, 3 for RGB
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

# second set of CONV => RELU => POOL layers
model.add(Conv2D(50, (5,5), padding="same"))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

# first (and only) set of FC => RELU layers
model.add(Flatten())
model.add(Dense(500))
model.add(Activation("relu"))

# softmax classifier
model.add(Dense(6)) #6 classes
model.add(Activation("softmax"))

opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="sparse_categorical_crossentropy", optimizer=opt, metrics=["accuracy"])

model.summary()


# train the model
print("[INFO] training network...")
H = model.fit(train, batch_size=BS,
              validation_data=val,
              epochs=EPOCHS, verbose=1)

# Plot the training accuracy and loss
plt.figure()
plt.plot(H.history["accuracy"], label="train_acc")
plt.plot(H.history["val_accuracy"], label="val_acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

print("TRAINING COMPLETE------------")
#evaluating the model after training
test_loss, test_acc = model.evaluate(test)
print(test_acc)

=======
# -*- coding: utf-8 -*-
"""COE70B Data Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12W1-3t_YDnDUGKUz5l8tGftkE9gaOtLX
"""

import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt

# This line loads the data in batches of 32 and also does a variety of other useful functions on the data
data = tf.keras.utils.image_dataset_from_directory('Sorted_Images');

data_iterator = data.as_numpy_iterator()

class_labels = ["No line","Sharp Left","Sharp Right","Slight Left","Slight Right","Straight"]

data = data.map(lambda x,y: (x/255, y))
scaled_iterator = data.as_numpy_iterator();

train_size = 12
val_size = 3
test_size = 3

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense
from tensorflow.keras.optimizers import Adam

# initialize the number of epochs to train for, initial learning rate,and batch size
EPOCHS = 5
INIT_LR = 1e-3
BS = 17

# initialize the model
print("[INFO] compiling model...")
model = Sequential()

#first set of CONV=> RELU => POOL layers
model.add(Conv2D(20, (5, 5), padding="same", input_shape=(256,256,3))) #256x256 image, 3 for RGB
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

# second set of CONV => RELU => POOL layers
model.add(Conv2D(50, (5,5), padding="same"))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

# first (and only) set of FC => RELU layers
model.add(Flatten())
model.add(Dense(500))
model.add(Activation("relu"))

# softmax classifier
model.add(Dense(6)) #6 classes
model.add(Activation("softmax"))

opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="sparse_categorical_crossentropy", optimizer=opt, metrics=["accuracy"])

model.summary()


# train the model
print("[INFO] training network...")
H = model.fit(train, batch_size=BS,
              validation_data=val,
              epochs=EPOCHS, verbose=1)

# Plot the training accuracy and loss
plt.figure()
plt.plot(H.history["accuracy"], label="train_acc")
plt.plot(H.history["val_accuracy"], label="val_acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

print("TRAINING COMPLETE------------")
#evaluating the model after training
test_loss, test_acc = model.evaluate(test)
print(test_acc)

>>>>>>> 7220362f2f682b1a61a112c5e46e746a6b1a7b20
=======
# -*- coding: utf-8 -*-
"""COE70B Data Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12W1-3t_YDnDUGKUz5l8tGftkE9gaOtLX
"""

import numpy as np
import tensorflow as tf
from matplotlib import pyplot as plt

# This line loads the data in batches of 32 and also does a variety of other useful functions on the data
data = tf.keras.utils.image_dataset_from_directory('Sorted_Images');

data_iterator = data.as_numpy_iterator()

class_labels = ["No line","Sharp Left","Sharp Right","Slight Left","Slight Right","Straight"]

data = data.map(lambda x,y: (x/255, y))
scaled_iterator = data.as_numpy_iterator();

train_size = 12
val_size = 3
test_size = 3

train = data.take(train_size)
val = data.skip(train_size).take(val_size)
test = data.skip(train_size+val_size).take(test_size)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Flatten, Dense
from tensorflow.keras.optimizers import Adam

# initialize the number of epochs to train for, initial learning rate,and batch size
EPOCHS = 5
INIT_LR = 1e-3
BS = 17

# initialize the model
print("[INFO] compiling model...")
model = Sequential()

#first set of CONV=> RELU => POOL layers
model.add(Conv2D(20, (5, 5), padding="same", input_shape=(256,256,3))) #256x256 image, 3 for RGB
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

# second set of CONV => RELU => POOL layers
model.add(Conv2D(50, (5,5), padding="same"))
model.add(Activation("relu"))
model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))

# first (and only) set of FC => RELU layers
model.add(Flatten())
model.add(Dense(500))
model.add(Activation("relu"))

# softmax classifier
model.add(Dense(6)) #6 classes
model.add(Activation("softmax"))

opt = Adam(learning_rate=INIT_LR, decay=INIT_LR / EPOCHS)
model.compile(loss="sparse_categorical_crossentropy", optimizer=opt, metrics=["accuracy"])

model.summary()


# train the model
print("[INFO] training network...")
H = model.fit(train, batch_size=BS,
              validation_data=val,
              epochs=EPOCHS, verbose=1)

# Plot the training accuracy and loss
plt.figure()
plt.plot(H.history["accuracy"], label="train_acc")
plt.plot(H.history["val_accuracy"], label="val_acc")
plt.title("Training and Validation Accuracy")
plt.xlabel("Epoch")
plt.ylabel("Accuracy")
plt.legend()
plt.show()

print("TRAINING COMPLETE------------")
#evaluating the model after training
test_loss, test_acc = model.evaluate(test)
print(test_acc)

>>>>>>> 7220362f2f682b1a61a112c5e46e746a6b1a7b20
model.save("model.h5")